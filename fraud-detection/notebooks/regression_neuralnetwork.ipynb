{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b610cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7d5ce8c73890>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import fraud_detection as fd\n",
    "from fraud_detection.model_comparison import train_regression_model\n",
    "\n",
    "path = Path(\"../data/transformed_label_and_damage.parquet\")\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bfd3606",
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_features = [\n",
    "    \"max_product_price\",\n",
    "    \"has_positive_price_difference\",\n",
    "    \"has_bakery\",\n",
    "    \"time_to_first_scan\",\n",
    "    \"popularity_max\",\n",
    "    \"has_age_restricted\",\n",
    "    \"cash_desk\",\n",
    "    \"transaction_duration_seconds\",\n",
    "    \"feedback_low\",\n",
    "    \"feedback_middle\",\n",
    "    \"feedback_high\",\n",
    "    \"feedback_top\",\n",
    "    \"store_id\",\n",
    "    \"location\",\n",
    "    \"urbanization\",\n",
    "    \"has_voided\",\n",
    "    \"has_sold_by_weight\",\n",
    "    \"has_limited_time_offers\",\n",
    "    \"has_fruits_vegetables\",\n",
    "    \"has_missing\",\n",
    "    \"has_camera_detected_wrong_product\",\n",
    "    \"day_of_week\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec5c665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regression(seed=42):\n",
    "    X, y = fd.data_loader.load_data_np(path, drop_features=useless_features)\n",
    "    model = fd.neuralnets.train_nn.getNN_regressor(X.shape[1])\n",
    "\n",
    "    return fd.model_comparison.train_regression_model(model, X, y, test_size=0.2, seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaf1a06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118117, 2)\n",
      "=> Starting training\n",
      "=> epoch: 1, loss: 2.5073, duration: 1.9763712882995605\n",
      "MSE          2.51\n",
      "RMSE         1.58\n",
      "MAE          0.33\n",
      "R2          -0.00\n",
      "-- train and test duration: 3.027101993560791\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 2, loss: 2.5104, duration: 2.0598018169403076\n",
      "MSE          2.51\n",
      "RMSE         1.58\n",
      "MAE          0.31\n",
      "R2          -0.00\n",
      "-- train and test duration: 3.1305623054504395\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 3, loss: 2.4892, duration: 2.2531394958496094\n",
      "MSE          2.50\n",
      "RMSE         1.58\n",
      "MAE          0.38\n",
      "R2           0.00\n",
      "-- train and test duration: 3.331793785095215\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 4, loss: 2.3647, duration: 1.9640898704528809\n",
      "MSE          2.25\n",
      "RMSE         1.50\n",
      "MAE          0.48\n",
      "R2           0.10\n",
      "-- train and test duration: 3.014293909072876\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 5, loss: 2.1109, duration: 2.2328007221221924\n",
      "MSE          1.89\n",
      "RMSE         1.37\n",
      "MAE          0.24\n",
      "R2           0.25\n",
      "-- train and test duration: 3.5335185527801514\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 6, loss: 1.9951, duration: 2.1201529502868652\n",
      "MSE          1.79\n",
      "RMSE         1.34\n",
      "MAE          0.26\n",
      "R2           0.29\n",
      "-- train and test duration: 3.2023558616638184\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 7, loss: 1.9212, duration: 2.1099627017974854\n",
      "MSE          1.70\n",
      "RMSE         1.30\n",
      "MAE          0.35\n",
      "R2           0.32\n",
      "-- train and test duration: 3.382587194442749\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 8, loss: 1.8153, duration: 2.0506529808044434\n",
      "MSE          1.50\n",
      "RMSE         1.23\n",
      "MAE          0.25\n",
      "R2           0.40\n",
      "-- train and test duration: 3.141772747039795\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 9, loss: 1.7961, duration: 2.0411953926086426\n",
      "MSE          1.48\n",
      "RMSE         1.22\n",
      "MAE          0.26\n",
      "R2           0.41\n",
      "-- train and test duration: 3.106252431869507\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 10, loss: 1.7136, duration: 2.178018808364868\n",
      "MSE          1.52\n",
      "RMSE         1.23\n",
      "MAE          0.24\n",
      "R2           0.39\n",
      "-- train and test duration: 3.2910678386688232\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 11, loss: 1.7172, duration: 2.1015212535858154\n",
      "MSE          1.48\n",
      "RMSE         1.22\n",
      "MAE          0.22\n",
      "R2           0.41\n",
      "-- train and test duration: 3.1966536045074463\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 12, loss: 1.7106, duration: 2.159963846206665\n",
      "MSE          1.65\n",
      "RMSE         1.28\n",
      "MAE          0.30\n",
      "R2           0.34\n",
      "-- train and test duration: 3.4748313426971436\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 13, loss: 1.6734, duration: 2.1103665828704834\n",
      "MSE          1.53\n",
      "RMSE         1.24\n",
      "MAE          0.24\n",
      "R2           0.39\n",
      "-- train and test duration: 3.227491855621338\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 14, loss: 1.6324, duration: 2.057096481323242\n",
      "MSE          1.46\n",
      "RMSE         1.21\n",
      "MAE          0.23\n",
      "R2           0.42\n",
      "-- train and test duration: 3.317124366760254\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 15, loss: 1.6252, duration: 2.0321247577667236\n",
      "MSE          1.39\n",
      "RMSE         1.18\n",
      "MAE          0.22\n",
      "R2           0.45\n",
      "-- train and test duration: 3.114389657974243\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 16, loss: 1.6251, duration: 2.02117919921875\n",
      "MSE          1.39\n",
      "RMSE         1.18\n",
      "MAE          0.22\n",
      "R2           0.45\n",
      "-- train and test duration: 3.0835719108581543\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 17, loss: 1.5930, duration: 2.1628994941711426\n",
      "MSE          1.40\n",
      "RMSE         1.18\n",
      "MAE          0.25\n",
      "R2           0.44\n",
      "-- train and test duration: 3.2290449142456055\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 18, loss: 1.5934, duration: 2.033125638961792\n",
      "MSE          1.38\n",
      "RMSE         1.17\n",
      "MAE          0.30\n",
      "R2           0.45\n",
      "-- train and test duration: 3.183964252471924\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 19, loss: 1.5588, duration: 2.0100486278533936\n",
      "MSE          1.42\n",
      "RMSE         1.19\n",
      "MAE          0.17\n",
      "R2           0.43\n",
      "-- train and test duration: 3.292203664779663\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 20, loss: 1.5392, duration: 2.0626606941223145\n",
      "MSE          1.40\n",
      "RMSE         1.18\n",
      "MAE          0.19\n",
      "R2           0.44\n",
      "-- train and test duration: 3.1478543281555176\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 21, loss: 1.5245, duration: 2.1731016635894775\n",
      "MSE          1.37\n",
      "RMSE         1.17\n",
      "MAE          0.15\n",
      "R2           0.45\n",
      "-- train and test duration: 3.4841885566711426\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 22, loss: 1.5166, duration: 2.069232702255249\n",
      "MSE          1.34\n",
      "RMSE         1.16\n",
      "MAE          0.19\n",
      "R2           0.47\n",
      "-- train and test duration: 3.1605770587921143\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 23, loss: 1.5382, duration: 2.135779857635498\n",
      "MSE          1.30\n",
      "RMSE         1.14\n",
      "MAE          0.19\n",
      "R2           0.48\n",
      "-- train and test duration: 3.2174341678619385\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 24, loss: 1.7185, duration: 2.2185158729553223\n",
      "MSE          1.51\n",
      "RMSE         1.23\n",
      "MAE          0.29\n",
      "R2           0.40\n",
      "-- train and test duration: 3.341826915740967\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 25, loss: 1.6061, duration: 1.9327213764190674\n",
      "MSE          1.47\n",
      "RMSE         1.21\n",
      "MAE          0.27\n",
      "R2           0.41\n",
      "-- train and test duration: 2.963975191116333\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 26, loss: 1.5775, duration: 1.9446609020233154\n",
      "MSE          1.34\n",
      "RMSE         1.16\n",
      "MAE          0.26\n",
      "R2           0.47\n",
      "-- train and test duration: 3.1767449378967285\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 27, loss: 1.4911, duration: 2.0030393600463867\n",
      "MSE          1.27\n",
      "RMSE         1.13\n",
      "MAE          0.21\n",
      "R2           0.49\n",
      "-- train and test duration: 3.063965320587158\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=> epoch: 28, loss: 1.4793, duration: 1.9905970096588135\n",
      "MSE          1.32\n",
      "RMSE         1.15\n",
      "MAE          0.15\n",
      "R2           0.47\n",
      "-- train and test duration: 3.233484983444214\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Stopping training early due to low MAE\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m reg = \u001b[43mtrain_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mtrain_regression\u001b[39m\u001b[34m(seed)\u001b[39m\n\u001b[32m      2\u001b[39m X, y = fd.data_loader.load_data_np(path, drop_features=useless_features)\n\u001b[32m      3\u001b[39m model = fd.neuralnets.train_nn.getNN_regressor(X.shape[\u001b[32m1\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_comparison\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_regression_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hagen/projektpraktikum/projektpraktikum-datascience/fraud-detection/src/fraud_detection/model_comparison.py:115\u001b[39m, in \u001b[36mtrain_regression_model\u001b[39m\u001b[34m(model, X, targets, test_size, seed)\u001b[39m\n\u001b[32m    112\u001b[39m model.fit(X_train, y_train)\n\u001b[32m    113\u001b[39m preds = model.predict(X_test)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m bew = \u001b[43mmetrics\u001b[49m\u001b[43m.\u001b[49m\u001b[43mregression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m metrics.print_metrics(bew)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model, bew\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hagen/projektpraktikum/projektpraktikum-datascience/fraud-detection/src/fraud_detection/metrics.py:82\u001b[39m, in \u001b[36mregression\u001b[39m\u001b[34m(predictions, targets)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mregression\u001b[39m(predictions, targets):\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     mse = \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m     rmse = np.sqrt(mse)\n\u001b[32m     84\u001b[39m     mae = mean_absolute_error(targets, predictions)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hagen/projektpraktikum/projektpraktikum-datascience/fraud-detection/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hagen/projektpraktikum/projektpraktikum-datascience/fraud-detection/.venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:580\u001b[39m, in \u001b[36mmean_squared_error\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput)\u001b[39m\n\u001b[32m    530\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[32m    531\u001b[39m \n\u001b[32m    532\u001b[39m \u001b[33;03mRead more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    576\u001b[39m \u001b[33;03m0.825...\u001b[39;00m\n\u001b[32m    577\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    578\u001b[39m xp, _ = get_namespace(y_true, y_pred, sample_weight, multioutput)\n\u001b[32m    579\u001b[39m _, y_true, y_pred, sample_weight, multioutput = (\n\u001b[32m--> \u001b[39m\u001b[32m580\u001b[39m     \u001b[43m_check_reg_targets_with_floating_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    583\u001b[39m )\n\u001b[32m    584\u001b[39m output_errors = _average((y_true - y_pred) ** \u001b[32m2\u001b[39m, axis=\u001b[32m0\u001b[39m, weights=sample_weight)\n\u001b[32m    586\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(multioutput, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hagen/projektpraktikum/projektpraktikum-datascience/fraud-detection/.venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:207\u001b[39m, in \u001b[36m_check_reg_targets_with_floating_dtype\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput, xp)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check_reg_targets_with_floating_dtype\u001b[39m(\n\u001b[32m    158\u001b[39m     y_true, y_pred, sample_weight, multioutput, xp=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    159\u001b[39m ):\n\u001b[32m    160\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Ensures y_true, y_pred, and sample_weight correspond to same regression task.\u001b[39;00m\n\u001b[32m    161\u001b[39m \n\u001b[32m    162\u001b[39m \u001b[33;03m    Extends `_check_reg_targets` by automatically selecting a suitable floating-point\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    205\u001b[39m \u001b[33;03m        correct keyword.\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     dtype_name = \u001b[43m_find_matching_floating_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m     y_type, y_true, y_pred, sample_weight, multioutput = _check_reg_targets(\n\u001b[32m    210\u001b[39m         y_true, y_pred, sample_weight, multioutput, dtype=dtype_name, xp=xp\n\u001b[32m    211\u001b[39m     )\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m y_type, y_true, y_pred, sample_weight, multioutput\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hagen/projektpraktikum/projektpraktikum-datascience/fraud-detection/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:592\u001b[39m, in \u001b[36m_find_matching_floating_dtype\u001b[39m\u001b[34m(xp, *arrays)\u001b[39m\n\u001b[32m    581\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_find_matching_floating_dtype\u001b[39m(*arrays, xp):\n\u001b[32m    582\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Find a suitable floating point dtype when computing with arrays.\u001b[39;00m\n\u001b[32m    583\u001b[39m \n\u001b[32m    584\u001b[39m \u001b[33;03m    If any of the arrays are floating point, return the dtype with the highest\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    590\u001b[39m \u001b[33;03m    instance), return the default floating point dtype for the namespace.\u001b[39;00m\n\u001b[32m    591\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m592\u001b[39m     dtyped_arrays = [\u001b[43mxp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(a, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m    593\u001b[39m     floating_dtypes = [\n\u001b[32m    594\u001b[39m         a.dtype \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m dtyped_arrays \u001b[38;5;28;01mif\u001b[39;00m xp.isdtype(a.dtype, \u001b[33m\"\u001b[39m\u001b[33mreal floating\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    595\u001b[39m     ]\n\u001b[32m    596\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m floating_dtypes:\n\u001b[32m    597\u001b[39m         \u001b[38;5;66;03m# Return the floating dtype with the highest precision:\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hagen/projektpraktikum/projektpraktikum-datascience/fraud-detection/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/numpy/_aliases.py:116\u001b[39m, in \u001b[36masarray\u001b[39m\u001b[34m(obj, dtype, device, copy, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    114\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33masarray(copy=False) requires a newer version of NumPy.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hagen/projektpraktikum/projektpraktikum-datascience/fraud-detection/.venv/lib/python3.12/site-packages/torch/_tensor.py:1225\u001b[39m, in \u001b[36mTensor.__array__\u001b[39m\u001b[34m(self, dtype)\u001b[39m\n\u001b[32m   1223\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor.__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype=dtype)\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1225\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1227\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.numpy().astype(dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "reg = train_regression(seed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
