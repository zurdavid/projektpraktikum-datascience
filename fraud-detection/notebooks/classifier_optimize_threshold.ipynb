{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5a80f59",
   "metadata": {},
   "source": [
    "# Optimierung des Schwellwerts für das Klassifikationsmodell\n",
    "\n",
    "In diesem Notebook wird untersucht, ob eine Optimierung des Schwellwerts für das Klassifikationsmodell sinnvoll ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c3db1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize_scalar\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import fraud_detection as fd\n",
    "from fraud_detection import data_loader, metrics\n",
    "from fraud_detection.models.costoptim import bewertung\n",
    "\n",
    "datapath = \"../data/transformed_label_and_damage.parquet\"\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20685dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adfc7104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lade Daten ohne die nutzlosen Features\n",
    "X, targets = data_loader.load_data_np(datapath, drop_features=data_loader.useless_features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, targets, test_size=0.2, random_state=seed, stratify=targets[:, 1] > 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1229db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bewertung(yhat, y, damage):\n",
    "    \"\"\"\n",
    "    Bewertung der Vorhersagen mittels der Bewertungsfunktion der Wertkauf GmbH.\n",
    "    \"\"\"\n",
    "    res = np.zeros(yhat.shape)\n",
    "    # Case 1: FRAUD caught\n",
    "    res += ((y == 1) & (yhat == 1)) * 5\n",
    "    # Case 2: False positive\n",
    "    res -= ((y == 0) & (yhat == 1)) * 10\n",
    "    # Case 3: FRAUD missed\n",
    "    res -= ((y == 1) & (yhat == 0)) * damage\n",
    "    return res.sum()\n",
    "\n",
    "def calc_bewertung_for_given_threshold(probs, theta_threshold, label_true, damage_true):\n",
    "    \"\"\"\n",
    "    Berechnet die Bewertung der Vorhersagen basierend auf den gegebenen Parametern.\n",
    "    \"\"\"\n",
    "    yhat = probs > theta_threshold\n",
    "    return bewertung(yhat, label_true, damage_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4afe5545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_threshold(clf, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Optimiert die Entscheidungsschwelle für das gegebene Modell und die Trainingsdaten.\n",
    "    \"\"\"\n",
    "    probs_train = clf.predict_proba(X_train)[:, 1]\n",
    "    def objective(theta):\n",
    "        values = calc_bewertung_for_given_threshold(probs_train, theta, y_train[:, 0], y_train[:, 1])\n",
    "        return -np.mean(values)  # negative because we minimize\n",
    "\n",
    "    res = minimize_scalar(objective, bounds=(0.1, 1.0), method='bounded')\n",
    "    cost_tp = res.x\n",
    "    return cost_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3320bdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_threshold(clf, X_test, y_test, threshold):\n",
    "    \"\"\"\n",
    "    Bewertet die Vorhersagen des Modells auf den Testdaten unter Verwendung der gegebenen Threshold.\n",
    "    \"\"\"\n",
    "    probs_test = clf.predict_proba(X_test)[:, 1]\n",
    "    yhat = probs_test > threshold\n",
    "    return metrics.bewertung(probs_test, yhat, y_test[:, 0], y_test[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d7e264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_and_evaluate(clf, X_train, y_train, X_test, y_test):\n",
    "    probs_baseline = clf.predict_proba(X_test)[:, 1]\n",
    "    preds_baseline = clf.predict(X_test)\n",
    "\n",
    "    metrics_baseline = metrics.bewertung(probs_baseline, preds_baseline, y_test[:, 0], y_test[:, 1])\n",
    "\n",
    "    opt_threshold = optimize_threshold(clf, X_train, y_train)\n",
    "    metrics_opt = evaluate_threshold(clf, X_test, y_test, opt_threshold)\n",
    "\n",
    "    diff = metrics_baseline[\"Bewertung\"] - metrics_opt[\"Bewertung\"]\n",
    "    if diff < 0:\n",
    "        print(f\"Optimized threshold ({opt_threshold:.2f}) improved the score by {-diff:.2f} points.\")\n",
    "    else:\n",
    "        print(f\"Optimized threshold ({opt_threshold:.2f}) did not improve the score, difference: {diff:.2f}.\")\n",
    "\n",
    "    return { \"baseline\": metrics_baseline, \"optimized_threshold\": metrics_opt,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a68be075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(X, targets, n_splits=5, n_repeats=1, random_state=42):\n",
    "\n",
    "    # Initialize the RepeatedStratifiedKFold\n",
    "    skf = RepeatedStratifiedKFold(\n",
    "        n_splits=n_splits, n_repeats=n_repeats, random_state=random_state\n",
    "    )\n",
    "\n",
    "    model_metrics = []\n",
    "\n",
    "    for i, (train_idx, test_idx) in enumerate(skf.split(X, targets[:, 0])):\n",
    "        clf = XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=5,\n",
    "            learning_rate=0.1,\n",
    "            objective=\"binary:logistic\",\n",
    "        )\n",
    "        clf.fit(X[train_idx,:], targets[train_idx, 0])\n",
    "\n",
    "        mm = optimize_and_evaluate(clf, X[train_idx], targets[train_idx], X[test_idx], targets[test_idx])\n",
    "        # optimize on test set to check if functions work\n",
    "        # mm = optimize_and_evaluate(clf, X[test_idx], targets[test_idx], X[test_idx], targets[test_idx])\n",
    "        model_metrics.append(mm)\n",
    "\n",
    "    return model_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6729123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized threshold (0.45) did not improve the score, difference: 135.67.\n",
      "Optimized threshold (0.47) improved the score by 52.23 points.\n",
      "Optimized threshold (0.39) did not improve the score, difference: 102.49.\n",
      "Optimized threshold (0.33) did not improve the score, difference: 180.37.\n",
      "Optimized threshold (0.43) did not improve the score, difference: 113.34.\n",
      "Optimized threshold (0.44) did not improve the score, difference: 9.80.\n",
      "Optimized threshold (0.40) did not improve the score, difference: 66.55.\n",
      "Optimized threshold (0.45) did not improve the score, difference: 135.52.\n",
      "Optimized threshold (0.45) improved the score by 30.87 points.\n",
      "Optimized threshold (0.37) did not improve the score, difference: 115.04.\n",
      "Optimized threshold (0.43) did not improve the score, difference: 6.54.\n",
      "Optimized threshold (0.39) did not improve the score, difference: 222.65.\n",
      "Optimized threshold (0.45) improved the score by 43.73 points.\n",
      "Optimized threshold (0.35) did not improve the score, difference: 123.05.\n",
      "Optimized threshold (0.45) did not improve the score, difference: 8.84.\n",
      "Optimized threshold (0.44) improved the score by 28.40 points.\n",
      "Optimized threshold (0.43) did not improve the score, difference: 255.65.\n",
      "Optimized threshold (0.38) did not improve the score, difference: 38.96.\n",
      "Optimized threshold (0.38) improved the score by 41.42 points.\n",
      "Optimized threshold (0.44) did not improve the score, difference: 8.37.\n",
      "Optimized threshold (0.47) improved the score by 64.72 points.\n",
      "Optimized threshold (0.45) did not improve the score, difference: 1.52.\n",
      "Optimized threshold (0.40) did not improve the score, difference: 198.67.\n",
      "Optimized threshold (0.34) improved the score by 6.83 points.\n",
      "Optimized threshold (0.44) did not improve the score, difference: 108.49.\n"
     ]
    }
   ],
   "source": [
    "model_metrics = run_experiment(X, targets, n_splits=5, n_repeats=5, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaaf303",
   "metadata": {},
   "source": [
    "Die Differenz von Baseline und Resultat mit Optimierung des Entscheidungsschwellwertes ist positiv. Das bedeutet, dass die Optimierung des Entscheidungsschwellwertes generell keine Verbesserung bringt. Die Unterschiede sind jedoch gering, was darauf hindeutet, dass die Optimierung des Entscheidungsschwellwertes in diesem Fall keinen signifikanten Einfluss auf das Ergebnis hat.\n",
    "\n",
    "Der Schwellwert des Model von 0.5 ist hochstwahrscheinlich schon relativ nah am Optimum, sodass eine weitere Optimierung des Schwellwerte keine Verbesserung mehr bringt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f2932f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(62.532799999999995)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([m[\"baseline\"][\"Bewertung\"] - m[\"optimized_threshold\"][\"Bewertung\"] for m in model_metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ea9e63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
